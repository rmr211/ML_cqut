{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个layer\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "    def backward(self, input, grad_output):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Relu层\n",
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,input):\n",
    "        return np.maximum(0,input) # relu函数为max(0,x)\n",
    "    def backward(self,input,grad_output):\n",
    "        relu_grad = input>0        #relu函数导数为1 if x>0 else 0\n",
    "        return grad_output*relu_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "            pass\n",
    "    \n",
    "    def _sigmoid(self,x):\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "    \n",
    "    def forward(self,input):\n",
    "        return self._sigmoid(input)\n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        sigmoid_grad = self._sigmoid(input)*(1-self._sigmoid(input))\n",
    "        return grad_output*sigmoid_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def _tanh(self,x):\n",
    "        return np.tanh(x)\n",
    "    def forward(self,input):\n",
    "        return self._tanh(input)\n",
    "    def backward(self, input, grad_output):\n",
    "        grad_tanh = 1-(self._tanh(input))**2\n",
    "        return grad_output*grad_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.randn(input_units, output_units)*0.01\n",
    "        self.biases = np.zeros(output_units)\n",
    "    def forward(self,input):\n",
    "        return np.dot(input,self.weights)+self.biases\n",
    "    def backward(self,input,grad_output):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(input.T,grad_output)/input.shape[0]\n",
    "        grad_biases = grad_output.mean(axis=0)\n",
    "        self.weights = self.weights - self.learning_rate*grad_weights\n",
    "        self.biases = self.biases - self.learning_rate*grad_biases\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Dense(1,50))\n",
    "network.append(Tanh())\n",
    "network.append(Dense(50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(network,X):\n",
    "    activations = []\n",
    "    input = X\n",
    "    for layer in network:\n",
    "        activations.append(layer.forward(input))\n",
    "        input = activations[-1]\n",
    "                \n",
    "    assert len(activations) == len(network)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network,X):\n",
    "    logits = forward(network,X)[-1]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network,X,y):    \n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  \n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    # 这里的损失函数需要自己定义\n",
    "    loss = np.square(logits - y).sum()\n",
    "    loss_grad = 2.0*(logits-y)\n",
    "    \n",
    "    for layer_i in range(len(network))[::-1]:\n",
    "        layer = network[layer_i]\n",
    "        loss_grad = layer.backward(layer_inputs[layer_i],loss_grad) #grad w.r.t. input, also weight updates\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.linspace(-np.pi,0.7 * np.pi,140).reshape(140,-1)\n",
    "y_train = np.sin(x_train)\n",
    "x_test = np.linspace(np.pi*0.7,np.pi,60).reshape(60,-1)\n",
    "y_test = np.sin(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33377588807050196\n",
      "0.32130373044270777\n",
      "0.21390993228754115\n",
      "0.19632380877679514\n",
      "0.26406608986941094\n",
      "0.26460237767513567\n",
      "0.17318275623760387\n",
      "0.15847483773755866\n",
      "0.2276963157509399\n",
      "0.39515380973541925\n",
      "0.14239455493283312\n",
      "0.23211395260996404\n",
      "0.16421716159319505\n",
      "0.1779528805777044\n",
      "0.19596180445312555\n",
      "0.24594655719865563\n",
      "0.15036849005276706\n",
      "0.18077882167409315\n",
      "0.17138408687781442\n",
      "0.269029640707632\n",
      "0.2633067882384181\n",
      "0.3216288061102249\n",
      "0.12758591083139192\n",
      "0.22572019158426354\n",
      "0.1825711787420027\n",
      "0.5059509655972037\n",
      "0.3027932887831939\n",
      "0.2715088876582787\n",
      "0.1649975451534979\n",
      "0.12601883330079025\n",
      "0.1450376501744069\n",
      "0.21199331058864038\n",
      "0.13326484393647736\n",
      "0.5080318867392426\n",
      "0.14736282401209866\n",
      "0.14195325736781542\n",
      "0.24306397721133458\n",
      "0.12237486919874686\n",
      "0.32502152484001967\n",
      "0.18428280228663516\n",
      "0.2066247470637079\n",
      "0.49741763261478034\n",
      "0.5115291953007004\n",
      "0.1966367264733273\n",
      "0.15523671545377418\n",
      "0.20287882043270725\n",
      "0.1695919156533425\n",
      "0.17115640188131498\n",
      "0.13946269432468106\n",
      "0.19181867860283258\n",
      "0.17869103597437105\n",
      "0.13665157642848716\n",
      "0.13433728940365844\n",
      "0.15882299705028402\n",
      "0.16175073427558215\n",
      "0.1811341623739371\n",
      "0.4942932134544792\n",
      "0.13923221552908613\n",
      "0.1638291180066546\n",
      "0.22945761579776808\n",
      "0.11433417886809724\n",
      "0.4904429158626867\n",
      "0.2680058510256672\n",
      "0.15480276849497768\n",
      "0.11337746856530681\n",
      "0.22145195096061907\n",
      "0.17517840430603948\n",
      "0.49195584670653075\n",
      "0.4892925291013041\n",
      "0.10684764250385544\n",
      "0.09929123164660333\n",
      "0.16751697643400337\n",
      "0.48819434198640727\n",
      "0.14711597692321152\n",
      "0.16792739896584322\n",
      "0.19269671099824826\n",
      "0.48616132328470507\n",
      "0.11646951280196319\n",
      "0.19342130808525074\n",
      "0.1344205556962857\n",
      "0.3312461249589336\n",
      "0.11129748318988086\n",
      "0.2512504371837255\n",
      "0.13662272178744284\n",
      "0.12056620032770698\n",
      "0.5011352133528476\n",
      "0.11638026814013344\n",
      "0.4930179841346839\n",
      "0.1210780766955783\n",
      "0.17755571701490266\n",
      "0.1146018110040295\n",
      "0.25836411402926035\n",
      "0.1071342536831119\n",
      "0.1628745732679697\n",
      "0.16397749932156264\n",
      "0.29624962975029223\n",
      "0.13016553763724464\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for h in range(3,100):\n",
    "    network = []\n",
    "    network.append(Dense(1,h))\n",
    "    network.append(Sigmoid())\n",
    "    network.append(Dense(h,1))\n",
    "    ll = []\n",
    "    for e in range(100000):\n",
    "        loss = train(network,x_train,y_train)\n",
    "        ll.append(loss)\n",
    "    print(np.mean(ll[-1000:]))\n",
    "    losses.append(np.mean(ll[-1000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
